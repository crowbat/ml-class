from __future__ import print_function
import keras
from keras.datasets import cifar10
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization
from keras.layers import Conv2D, MaxPooling2D
from keras.callbacks import ModelCheckpoint
from keras.applications.inception_v3 import InceptionV3
from keras.models import Model
import skimage

import os
import wandb
from wandb.keras import WandbCallback

run = wandb.init()
config = run.config
config.dropout = 0.25
config.dense_layer_nodes = 100
config.learn_rate = 0.01
config.batch_size = 32
config.epochs = 10

def setup_to_transfer_learn(model, base_model):
    """Freeze all layers and compile the model"""
    for layer in base_model.layers:
        layer.trainable = False
    model.compile(optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9),
                  loss='categorical_crossentropy', metrics=['accuracy'])


def add_new_last_layer(base_model, nb_classes):
    """Add last layer to the convnet
      Args:
        base_model: keras model excluding top
        nb_classes: # of classes
      Returns:
        new keras model with last layer
    """
    x = base_model.output
    x = Dense(256, activation='relu')(
        x)  # new FC layer, random init
    predictions = Dense(nb_classes, activation='softmax')(
        x)  # new softmax layer
    model = Model(inputs=base_model.input, outputs=predictions)
    return model

class_names = ['airplane','automobile','bird','cat','deer',
               'dog','frog','horse','ship','truck']
num_classes = len(class_names)

(X_train, y_train), (X_test, y_test) = cifar10.load_data()
num_training_ex = len(X_train)

# Convert class vectors to binary class matrices.
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

model = Sequential()
model.add(BatchNormalization(input_shape=X_train.shape[1:]))
model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))
model.add(Conv2D(32, (3, 3), padding='same',
                 input_shape=X_train.shape[1:], activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(32, (3, 3), padding='same',
                 input_shape=X_train.shape[1:], activation='relu'))
model.add(Conv2D(16, (3, 3), padding='same',
                 input_shape=X_train.shape[1:], activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(config.dropout))

model.add(Flatten())
model.add(Dense(1024, activation='relu'))
model.add(Dropout(config.dropout))
model.add(Dense(64, activation='relu'))
model.add(Dropout(config.dropout))
model.add(Dense(num_classes, activation='softmax'))

opt = keras.optimizers.SGD(lr=config.learn_rate)

# Let's train the model using RMSprop
model.load_weights("best_weights.hdf5")
model.compile(loss='categorical_crossentropy',
              optimizer=opt,
              metrics=['accuracy'])

X_train = X_train.astype('float32') / 255.
X_test = X_test.astype('float32') / 255.
#X_train_resized = [skimage.transform.resize(image, (299,299,1)) for image in X_train]
#X_test_resized = [skimage.transform.resize(image, (299,299,1)) for image in X_test]

datagen = ImageDataGenerator(width_shift_range=0.1)
datagen.fit(X_train)

checkpoint = ModelCheckpoint('best_weights.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')
wandb_callback = WandbCallback(data_type="image", labels=class_names)
cb_list = [checkpoint, wandb_callback]

# Fit the model on the batches generated by datagen.flow().
model.fit_generator(datagen.flow(X_train, y_train,
                                     batch_size=config.batch_size),
                        steps_per_epoch=X_train.shape[0] // config.batch_size,
                        epochs=config.epochs,
                        validation_data=(X_test, y_test),
                        workers=4,
                        callbacks=cb_list
)
"""
# setup model
base_model = InceptionV3(weights='imagenet', include_top=False, pooling="avg")
model = add_new_last_layer(base_model, num_classes)
model._is_graph_network = False

# transfer learning
setup_to_transfer_learn(model, base_model)

model.fit_generator(
    datagen.flow(X_train_resized, y_train, batch_size=config.batch_size),
    epochs=config.epochs,
    workers=2,
    steps_per_epoch=num_training_ex * 2 / config.batch_size,
    validation_data=(X_test_resized, y_test),
    validation_steps=num_training_ex / config.batch_size,
    callbacks=cb_list,
    class_weight='auto')


"""